{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Configura il percorso del JSON ===\n",
    "json_path = './4096_Palazzo_Maresa/project.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first level is a <class 'list'>, every item is called a task and usually represent a single data item\n",
      "Every task has properties: \n",
      " {'annotations', 'total_annotations', 'created_at', 'inner_id', 'total_predictions', 'cancelled_annotations', 'updated_by', 'updated_at', 'file_upload', 'last_comment_updated_at', 'drafts', 'predictions', 'comment_authors', 'data', 'unresolved_comment_count', 'project', 'id', 'meta', 'comment_count'}\n",
      "important properties are \"id\", \"inner_id\" and \"file_upload\"\n",
      "for example data[0][\"file_upload\"] : 692dfedd-d000.jpg\n",
      "\"data\", \"annotations\" and \"predictions\n",
      "\"data\" has only the \"image\"  properties /data/upload/4/692dfedd-d000.jpg\n",
      "\n",
      " let's focus on the 'annotations' part, it's a list always of length 0\n",
      "task[\"annotations\"][0] has properties: \n",
      " dict_keys(['id', 'completed_by', 'result', 'was_cancelled', 'ground_truth', 'created_at', 'updated_at', 'draft_created_at', 'lead_time', 'prediction', 'result_count', 'unique_id', 'import_id', 'last_action', 'task', 'project', 'updated_by', 'parent_prediction', 'parent_annotation', 'last_created_by'])\n",
      "\"all the significant part is inside the \"result\" part, where there is a list of actual annotations\n",
      "task[\"annotations][0][\"result][0] has properties: \n",
      " dict_keys(['original_width', 'original_height', 'image_rotation', 'value', 'id', 'from_name', 'to_name', 'type', 'origin'])\n",
      "for this dataset, \"type\" is \"polygonlabels\" or \"rectanglelabels\"\n",
      "\n",
      " \n",
      " all the relevant informations are inside \"value\" and are shown below\n",
      "    rectanglelabels: {'wide'}\n",
      "    polygonlabels: {'crack', 'crack_orizz'}\n"
     ]
    }
   ],
   "source": [
    "def structure(data):\n",
    "    print(f'first level is a {type(data)}, every item is called a task and usually represent a single data item')\n",
    "    task_properties = set()\n",
    "    for item in data:\n",
    "        task_properties.update(item.keys())\n",
    "    print(f'Every task has properties: \\n {task_properties}')\n",
    "\n",
    "    print(f'important properties are \"id\", \"inner_id\" and \"file_upload\"')\n",
    "    print(f'for example data[0][\"file_upload\"] : {data[0][\"file_upload\"]}')\n",
    "\n",
    "    print('\"data\", \"annotations\" and \"predictions')\n",
    "    print(f'\"data\" has only the \"image\"  properties {data[0][\"data\"][\"image\"] }')\n",
    "\n",
    "    print(\"\\n let's focus on the 'annotations' part, it's a list always of length 0\")\n",
    "    print(f'task[\"annotations\"][0] has properties: \\n {data[0][\"annotations\"][0].keys()}')\n",
    "    print(f'\"all the significant part is inside the \"result\" part, where there is a list of actual annotations')\n",
    "    print(f'task[\"annotations][0][\"result][0] has properties: \\n {data[0][\"annotations\"][0][\"result\"][0].keys()}')\n",
    "    print('for this dataset, \"type\" is \"polygonlabels\" or \"rectanglelabels\"')\n",
    "    print('\\n \\n all the relevant informations are inside \"value\" and are shown below')\n",
    "\n",
    "\n",
    "    rectangles = set()\n",
    "    polygons = set()\n",
    "    for task in data:\n",
    "        for ann in task['annotations']:\n",
    "            for result in ann['result']:\n",
    "                #print(result)\n",
    "                v = result[\"value\"]\n",
    "                if \"rectanglelabels\" in v:\n",
    "                    rectangles.update(v[\"rectanglelabels\"])\n",
    "                if \"polygonlabels\" in v:\n",
    "                    polygons.update(v[\"polygonlabels\"])\n",
    "\n",
    "    print(f'    rectanglelabels: {rectangles}')        \n",
    "    print(f'    polygonlabels: {polygons}')        \n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    structure(data)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value properties if \"type\" is \"rectanglelabel\"\n",
    "{'x': 5.464334698260859, 'y': 64.4410458441532, 'width': 13.04915748838414, 'height': 12.88604301977935, 'rotation': 0, 'rectanglelabels': ['wide']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value properties if \"type\" is \"polygonlabel\"\n",
    "{'points': [[18.294286875131725, 49.46043678939206], ... [18.09069061025868, 49.46043678939206]], 'closed': True, 'polygonlabels': ['crack_orizz']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
